{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't just stop at game data. That's why I also wanted to collect. Player Data and team data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# webpage = open('../GIT_NO/NBA Players List (2023-2024).htm').read()\n",
    "\n",
    "# players = re.findall(r'<a [\\s\\S]*? href=\"(/basketball/player/.*/.*)\">', webpage)\n",
    "\n",
    "# players = list(set(players))\n",
    "# for i in range(len(players)):\n",
    "#     players[i] = players[i].split('\"')[0]\n",
    "    \n",
    "# players = list(map(lambda x: '' + x + \"/totals\", players))\n",
    "# players    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('player_links.txt', 'w') as f:\n",
    "#     for line in players:\n",
    "#         f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping\n",
    "\n",
    "Now to take the data out of the webpages\n",
    "\n",
    "For the player webpages it's a lot more of a simple design so we should be able to take everything out with one regex looking for \\<div class=\"table__inner\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"[redacted]\"\n",
    "\n",
    "fp = urllib.request.urlopen(url)\n",
    "mybytes = fp.read()\n",
    "\n",
    "webpage = mybytes.decode(\"utf8\")\n",
    "fp.close()\n",
    "\n",
    "# print(webpage)\n",
    "\n",
    "data = re.findall(r'(<div class=\"table__inner\">[\\s\\S]*?</main>)', webpage)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nba = re.findall(r'(<table class=\"table\">[\\s\\S]*?</table>)', data[0])\n",
    "Nba_stats = Nba[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_headers = re.findall(r'(<th class=\".*\">[\\s\\S]*?</th>)', Nba_stats)\n",
    "player_headers = list(map(lambda x: x.split('>')[1].split('<')[0], player_headers))\n",
    "player_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data = re.findall(r'(<td class=\".*\">[\\s\\S]*?</td>)', Nba_stats)\n",
    "player_data = [re.sub(r'(<td class=\\\".*\\\">|<\\/td>|<a [\\s\\S]*?>|<\\/a>|<div [\\s\\S]*?>[\\s\\S]*?>[\\s\\S]*?<\\/div>|\\n)','', data) for data in player_data]\n",
    "player_data = [re.sub(r'[\\s]+', '', data) for data in player_data]\n",
    "player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_obj = {player_headers[i]: [] for i in range(len(player_headers))}\n",
    "\n",
    "row_iterator = 0\n",
    "for i in range(len(player_data)):\n",
    "    if row_iterator == len(player_headers):\n",
    "        row_iterator = 0\n",
    "        player_obj[player_headers[row_iterator]].append(player_data[i])\n",
    "        row_iterator += 1\n",
    "    else:\n",
    "        player_obj[player_headers[row_iterator]].append(player_data[i])\n",
    "        row_iterator += 1\n",
    "        \n",
    "player_obj['Pts'] = player_obj['Pts'][0:len(player_obj['Pts']):2]\n",
    "player_obj['Reb'] = player_obj['Reb'][0:len(player_obj['Reb']):2]\n",
    "player_obj['Ast'] = player_obj['Ast'][0:len(player_obj['Ast']):2]\n",
    "\n",
    "player_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to convert the data types. Some these are Strings like W-L which could be better represented by a numpy array of size 2. Even the 2P column could be represented by it's floating point value to be more interpretable by machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "player_df = pd.DataFrame(player_obj)\n",
    "\n",
    "for index, row in player_df.iterrows():\n",
    "    player_df.at[index, 'W-L'] = np.array(player_df.at[index, 'W-L'].split('-'), dtype=int)\n",
    "    player_df.at[index, '2P'] = (int(player_df.at[index, '2P'].split('/')[0]) / int(player_df.at[index, '2P'].split('/')[1])) \n",
    "    # repeat for 3P, FT, FG \n",
    "    player_df.at[index, '3P'] = (int(player_df.at[index, '3P'].split('/')[0]) / int(player_df.at[index, '3P'].split('/')[1]))\n",
    "    player_df.at[index, 'FT'] = (int(player_df.at[index, 'FT'].split('/')[0]) / int(player_df.at[index, 'FT'].split('/')[1]))\n",
    "    player_df.at[index, 'FG'] = (int(player_df.at[index, 'FG'].split('/')[0]) / int(player_df.at[index, 'FG'].split('/')[1]))\n",
    "\n",
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team data\n",
    "\n",
    "Rinse and repeat for the teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
